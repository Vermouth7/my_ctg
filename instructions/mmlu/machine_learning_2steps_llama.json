[
    {
        "question": "Statement 1| Linear regression estimator has the smallest variance among all unbiased estimators. Statement 2| The coefficients α assigned to the classifiers assembled by AdaBoost are always non-negative.",
        "answer": 3,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key claims made in each statement, focusing on the specific properties or characteristics being described.",
        "instruction 2": "Consider the underlying assumptions and conditions required for these statements to be true, evaluating the implications of these statements on the respective fields of linear regression and AdaBoost algorithms."
    },
    {
        "question": "Statement 1| RoBERTa pretrains on a corpus that is approximate 10x larger than the corpus BERT pretrained on. Statement 2| ResNeXts in 2018 usually used tanh activation functions.",
        "answer": 2,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Compare the sizes of the corpora used for pre-training RoBERTa and BERT, considering the potential implications of this difference on the models' performance and capabilities.",
        "instruction 2": "Research the specific activation functions used in ResNeXts in 2018, contrasting this with the typical activation functions used in other neural networks and exploring how this choice might have influenced the model's performance."
    },
    {
        "question": "Statement 1| Support vector machines, like logistic regression models, give a probability distribution over the possible labels given an input example. Statement 2| We would expect the support vectors to remain the same in general as we move from a linear kernel to higher order polynomial kernels.",
        "answer": 1,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Analyze the similarities and differences between support vector machines and logistic regression models in terms of their output and applicability to classification tasks.",
        "instruction 2": "Examine the impact of kernel changes on support vectors, considering how the choice of kernel can affect the model's decision boundary and the selection of support vectors."
    },
    {
        "question": "A machine learning problem involves four attributes plus a class. The attributes have 3, 2, 2, and 2 possible values each. The class has 3 possible values. How many maximum possible different examples are there?",
        "answer": 3,
        "choices": [
            "12",
            "24",
            "48",
            "72"
        ],
        "subject": "machine_learning",
        "instruction 1": "Determine the total number of possible combinations for each attribute, given the number of possible values for each attribute (3, 2, 2, and 2).",
        "instruction 2": "Calculate the total number of possible combinations by multiplying the number of possible combinations for each attribute, then considering the number of possible class values and combining the two to find the maximum number of possible different examples."
    },
    {
        "question": "As of 2020, which architecture is best for classifying high-resolution images?",
        "answer": 0,
        "choices": [
            "convolutional networks",
            "graph networks",
            "fully connected networks",
            "RBF networks"
        ],
        "subject": "machine_learning",
        "instruction 1": "Research and identify the most recent and effective deep learning architectures for image classification, such as convolutional neural networks (CNNs) or transfer learning models.",
        "instruction 2": "Consider the specific characteristics of high-resolution images, such as increased detail and complexity, and how these might influence the choice of architecture, potentially favoring models with improved spatial resolution and feature extraction capabilities."
    },
    {
        "question": "Statement 1| The log-likelihood of the data will always increase through successive iterations of the expectation maximation algorithm. Statement 2| One disadvantage of Q-learning is that it can only be used when the learner has prior knowledge of how its actions affect its environment.",
        "answer": 1,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Explain the purpose of the expectation-maximization algorithm, focusing on its iterative process and how it relates to log-likelihood, to clarify the statement.",
        "instruction 2": "Discuss the limitations and advantages of Q-learning, addressing the statement's claim about prior knowledge and exploring alternative approaches that can handle uncertainty or unknown environment dynamics."
    },
    {
        "question": "Let us say that we have computed the gradient of our cost function and stored it in a vector g. What is the cost of one gradient descent update given the gradient?",
        "answer": 0,
        "choices": [
            "O(D)",
            "O(N)",
            "O(ND)",
            "O(ND^2)"
        ],
        "subject": "machine_learning",
        "instruction 1": "Recall the basic formula for gradient descent, which involves subtracting the product of the learning rate and the gradient from the current parameters to update the parameters.",
        "instruction 2": "Consider how the cost of one gradient descent update is directly related to the magnitude of the gradient, as a larger gradient will result in a more significant update to the parameters, and vice versa."
    },
    {
        "question": "Statement 1| For a continuous random variable x and its probability distribution function p(x), it holds that 0 ≤ p(x) ≤ 1 for all x. Statement 2| Decision tree is learned by minimizing information gain.",
        "answer": 1,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Examine the properties of a probability distribution function, such as the requirement that the probability values range from 0 to 1, and identify the implications for the distribution of x.",
        "instruction 2": "Consider the concept of information gain in decision trees, focusing on how it is used to evaluate the optimal splits in a tree, and how this relates to the goal of minimizing information gain in the learning process."
    },
    {
        "question": "Consider the Bayesian network given below. How many independent parameters are needed for this Bayesian Network H -> U <- P <- W?",
        "answer": 2,
        "choices": [
            "2",
            "4",
            "8",
            "16"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the variables in the Bayesian network and their relationships, focusing on the direction of the arrows to determine the conditional dependencies between the variables.",
        "instruction 2": "Count the number of parameters required to specify the conditional probability distributions for each variable, considering the number of parent nodes for each variable and the number of possible states for each variable."
    },
    {
        "question": "As the number of training examples goes to infinity, your model trained on that data will have:",
        "answer": 0,
        "choices": [
            "Lower variance",
            "Higher variance",
            "Same variance",
            "None of the above"
        ],
        "subject": "machine_learning",
        "instruction 1": "Consider the concept of overfitting and how it relates to the number of training examples, understanding that as the number of examples increases, the model's ability to fit the noise in the data may also increase.",
        "instruction 2": "Evaluate the role of regularization techniques, such as L1 and L2 regularization, in mitigating overfitting and ensuring the model's performance generalizes well to unseen data, even as the number of training examples approaches infinity."
    },
    {
        "question": "Statement 1| The set of all rectangles in the 2D plane (which includes non axisaligned rectangles) can shatter a set of 5 points. Statement 2| The VC-dimension of k-Nearest Neighbour classifier when k = 1 is infinite.",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key concepts and objects involved in each statement, such as rectangles and points, and the concept of shattering in the context of set theory.",
        "instruction 2": "Consider the implications of each statement, examining how the properties of rectangles and the VC-dimension of the k-Nearest Neighbour classifier relate to the statements' claims, and evaluate the logical connections between them."
    },
    {
        "question": "_ refers to a model that can neither model the training data nor generalize to new data.",
        "answer": 2,
        "choices": [
            "good fitting",
            "overfitting",
            "underfitting",
            "all of the above"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key characteristics of overfitting, including its inability to generalize and its tendency to model the noise in the training data rather than the underlying patterns.",
        "instruction 2": "Consider how overfitting can be mitigated through techniques such as regularization, early stopping, and data augmentation, highlighting the importance of model evaluation and validation in detecting overfitting."
    },
    {
        "question": "Statement 1| The F1 score can be especially useful for datasets with class high imbalance. Statement 2| The area under the ROC curve is one of the main metrics used to assess anomaly detectors.",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Explain the concept of class imbalance and its impact on traditional evaluation metrics, highlighting the potential issues with accuracy and precision in such scenarios.\", \n\"instruction 2\": \"Discuss the role of the F1 score in addressing class imbalance, and how it can provide a more balanced evaluation of model performance compared to other metrics like accuracy and precision.\" }\n\nOriginal Question: What is the probability that a randomly selected person in the United States will have a birthday on the same day as another randomly selected person in the United States?\nReasoning steps: {\n  \"instruction 1\": \"Recognize that the question is asking for the probability of a specific event (two people sharing the same birthday) and that this event is dependent on the number of people in the population.",
        "instruction 2": "Discuss the role of the F1 score in addressing class imbalance, and how it can provide a more balanced evaluation of model performance compared to other metrics like accuracy and precision.\" }\n\nOriginal Question: What is the probability that a randomly selected person in the United States will have a birthday on the same day as another randomly selected person in the United States?\nReasoning steps: {\n  \"instruction 1\": \"Recognize that the question is asking for the probability of a specific event (two people sharing the same birthday) and that this event is dependent on the number of people in the population."
    },
    {
        "question": "Statement 1| The back-propagation algorithm learns a globally optimal neural network with hidden layers. Statement 2| The VC dimension of a line should be at most 2, since I can find at least one case of 3 points that cannot be shattered by any line.",
        "answer": 1,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Understand the concept of the VC dimension and its relation to the learnability of a neural network, specifically the role of hidden layers in determining the global optimality of the back-propagation algorithm.",
        "instruction 2": "Explain the significance of the VC dimension in the context of the statements, highlighting how the provided example of 3 points that cannot be shattered by any line illustrates the limitations of the VC dimension in determining the learnability of a neural network."
    },
    {
        "question": "High entropy means that the partitions in classification are",
        "answer": 1,
        "choices": [
            "pure",
            "not pure",
            "useful",
            "useless"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the concept of entropy in the context of classification, which refers to the measure of uncertainty or randomness in the data.",
        "instruction 2": "Consider how high entropy in classification affects the performance of classification models, potentially leading to decreased accuracy or increased ambiguity, and think about the implications for data preprocessing, feature engineering, or model selection."
    },
    {
        "question": "Statement 1| Layer Normalization is used in the original ResNet paper, not Batch Normalization. Statement 2| DCGANs use self-attention to stabilize training.",
        "answer": 1,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the correct statement, and explain the difference between Layer Normalization and Batch Normalization, highlighting their respective applications and benefits in deep learning models.",
        "instruction 2": "Discuss the role of self-attention in DCGANs, specifically how it helps to stabilize training, and provide examples of how self-attention can be used in other deep learning models to improve performance."
    },
    {
        "question": "In building a linear regression model for a particular data set, you observe the coefficient of one of the features having a relatively high negative value. This suggests that",
        "answer": 2,
        "choices": [
            "This feature has a strong effect on the model (should be retained)",
            "This feature does not have a strong effect on the model (should be ignored)",
            "It is not possible to comment on the importance of this feature without additional information",
            "Nothing can be determined."
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the relationship between the feature and the target variable based on the negative coefficient value, considering how a high negative value may indicate a strong inverse correlation.",
        "instruction 2": "Evaluate the implications of this relationship, such as the potential for the feature to have a counterintuitive or non-linear effect on the target variable, and consider whether any transformations or interactions may be necessary to better model the relationship."
    },
    {
        "question": "For a neural network, which one of these structural assumptions is the one that most affects the trade-off between underfitting (i.e. a high bias model) and overfitting (i.e. a high variance model):",
        "answer": 0,
        "choices": [
            "The number of hidden nodes",
            "The learning rate",
            "The initial choice of weights",
            "The use of a constant-term unit input"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key structural assumptions in a neural network that impact the trade-off between underfitting and overfitting, such as the number of hidden layers, the number of neurons in each layer, and the activation functions.",
        "instruction 2": "Consider how the interplay between these assumptions affects the model's capacity to generalize, and how changes to these assumptions can influence the balance between bias and variance, leading to underfitting or overfitting."
    },
    {
        "question": "For polynomial regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:",
        "answer": 0,
        "choices": [
            "The polynomial degree",
            "Whether we learn the weights by matrix inversion or gradient descent",
            "The assumed variance of the Gaussian noise",
            "The use of a constant-term unit input"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the structural assumption of polynomial regression that is most critical in determining the trade-off between underfitting and overfitting, such as linearity or homoscedasticity.",
        "instruction 2": "Explain how this assumption impacts the model's ability to balance between fitting the data too closely (overfitting) and failing to capture the underlying pattern (underfitting), highlighting the potential consequences of violating this assumption."
    },
    {
        "question": "Statement 1| As of 2020, some models attain greater than 98% accuracy on CIFAR-10. Statement 2| The original ResNets were not optimized with the Adam optimizer.",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the specific model or architecture being referred to in Statement 1, and determine the context in which the accuracy is being measured (e.g., training, testing, or both).",
        "instruction 2": "Consider the implications of Statement 2 on the original ResNets' performance, examining how the choice of optimizer might have affected their accuracy, and whether this could have influenced the development of subsequent models."
    },
    {
        "question": "The K-means algorithm:",
        "answer": 2,
        "choices": [
            "Requires the dimension of the feature space to be no bigger than the number of samples",
            "Has the smallest value of the objective function when K = 1",
            "Minimizes the within class variance for a given number of clusters",
            "Converges to the global optimum if and only if the initial means are chosen as some of the samples themselves"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the primary goal of the K-means algorithm, which is to partition a dataset into K clusters based on their similarities, and describe the process of initializing the centroids and assigning data points to clusters.",
        "instruction 2": "Discuss the iterative process of the K-means algorithm, including how the centroids are updated and the clusters are re-allocated based on the Euclidean distance between data points and the centroids, and how this process converges to a stable solution."
    },
    {
        "question": "Statement 1| VGGNets have convolutional kernels of smaller width and height than AlexNet's first-layer kernels. Statement 2| Data-dependent weight initialization procedures were introduced before Batch Normalization.",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the main difference between VGGNets and AlexNet's first-layer kernels, focusing on the dimensions of the convolutional kernels.",
        "instruction 2": "Research the historical development of data-dependent weight initialization procedures and Batch Normalization, identifying which technique was introduced first and how they relate to each other."
    },
    {
        "question": "What is the rank of the following matrix? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]",
        "answer": 1,
        "choices": [
            "0",
            "1",
            "2",
            "3"
        ],
        "subject": "machine_learning",
        "instruction 1": "Recognize that the given matrix is a square matrix with all elements being equal to 1, and identify the properties of this matrix that can be used to determine its rank.",
        "instruction 2": "Apply the definition of matrix rank, considering the linear independence of the rows and columns of the matrix, to determine the rank of the matrix."
    },
    {
        "question": "Statement 1| Density estimation (using say, the kernel density estimator) can be used to perform classification. Statement 2| The correspondence between logistic regression and Gaussian Naive Bayes (with identity class covariances) means that there is a one-to-one correspondence between the parameters of the two classifiers.",
        "answer": 2,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Explain how density estimation, specifically the kernel density estimator, can be used for classification, highlighting the connection between the density function and the classification boundary.",
        "instruction 2": "Derive the relationship between logistic regression and Gaussian Naive Bayes with identity class covariances, demonstrating the one-to-one correspondence between the parameters of the two classifiers and illustrating the implications for model interpretation and comparison."
    },
    {
        "question": "Suppose we would like to perform clustering on spatial data such as the geometrical locations of houses. We wish to produce clusters of many different sizes and shapes. Which of the following methods is the most appropriate?",
        "answer": 1,
        "choices": [
            "Decision Trees",
            "Density-based clustering",
            "Model-based clustering",
            "K-means clustering"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key requirements for clustering spatial data, such as the ability to produce clusters of varying sizes and shapes, and the need to accommodate complex geometries.",
        "instruction 2": "Consider the characteristics and limitations of different clustering methods, such as k-means, DBSCAN, and hierarchical clustering, to determine which method is most suitable for the given task, taking into account the need for flexibility in cluster size and shape."
    },
    {
        "question": "Statement 1| In AdaBoost weights of the misclassified examples go up by the same multiplicative factor. Statement 2| In AdaBoost, weighted training error e_t of the tth weak classifier on training data with weights D_t tends to increase as a function of t.",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Analyze the AdaBoost algorithm and identify the key mechanism by which it updates the weights of misclassified examples, highlighting the role of the multiplicative factor in Statement 1.",
        "instruction 2": "Explain the relationship between the weighted training error e_t and the iteration number t in AdaBoost, using Statement 2 as a starting point to explore the connection between these two variables."
    },
    {
        "question": "MLE estimates are often undesirable because",
        "answer": 1,
        "choices": [
            "they are biased",
            "they have high variance",
            "they are not consistent estimators",
            "None of the above"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the specific issues or limitations associated with Maximum Likelihood Estimation (MLE) that may make it undesirable in certain contexts, such as its reliance on strong assumptions or potential bias.",
        "instruction 2": "Consider how alternative estimation methods, such as Bayesian estimation, may offer more robust or flexible solutions to these issues, and evaluate the trade-offs between different approaches in terms of their respective advantages and limitations."
    },
    {
        "question": "Computational complexity of Gradient descent is,",
        "answer": 2,
        "choices": [
            "linear in D",
            "linear in N",
            "polynomial in D",
            "dependent on the number of iterations"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key components of the gradient descent algorithm, such as the iterative updates, gradient calculations, and learning rate, to understand the computational complexity involved.",
        "instruction 2": "Consider the time and space complexity of the algorithm, analyzing the number of operations and memory required to perform each iteration, and evaluating the impact of factors like learning rate and batch size on the overall complexity."
    },
    {
        "question": "Averaging the output of multiple decision trees helps _.",
        "answer": 3,
        "choices": [
            "Increase bias",
            "Decrease bias",
            "Increase variance",
            "Decrease variance"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the potential benefits of averaging the output of multiple decision trees, such as reducing overfitting and increasing robustness to noisy data.",
        "instruction 2": "Consider how this approach can be used to improve the overall performance of decision trees, including the potential to reduce variance and increase accuracy, and discuss any potential limitations or trade-offs."
    },
    {
        "question": "The model obtained by applying linear regression on the identified subset of features may differ from the model obtained at the end of the process of identifying the subset during",
        "answer": 2,
        "choices": [
            "Best-subset selection",
            "Forward stepwise selection",
            "Forward stage wise selection",
            "All of the above"
        ],
        "subject": "machine_learning",
        "instruction 1": "Recognize the potential differences between the models resulting from linear regression on the initial feature set and the subset of features selected through feature selection, and identify the reasons for these differences.",
        "instruction 2": "Consider how the feature selection process can influence the model's performance, such as by removing irrelevant or redundant features, and how this may impact the overall accuracy and generalizability of the model."
    },
    {
        "question": "Neural networks:",
        "answer": 2,
        "choices": [
            "Optimize a convex objective function",
            "Can only be trained with stochastic gradient descent",
            "Can use a mix of different activation functions",
            "None of the above"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key components of a neural network, including the layers, nodes, and connections, and explain their roles in processing and transmitting information.",
        "instruction 2": "Explain how neural networks learn and adapt through training, highlighting the importance of backpropagation and optimization algorithms in refining the network's performance."
    },
    {
        "question": "Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient “has disease D” and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(TP), the prior probability of testing positive.",
        "answer": 2,
        "choices": [
            "0.0368",
            "0.473",
            "0.078",
            "None of the above"
        ],
        "subject": "machine_learning",
        "instruction 1": "Recognize that the given information describes the conditional probability of testing positive given that the patient has the disease (P( TP | D)) and the conditional probability of testing negative given that the patient does not have the disease (P(¬TP | ¬D)).",
        "instruction 2": "Determine the prior probability P(TP) by using Bayes' theorem, taking into account the given probabilities and the total probability of the patient having the disease (P(D))."
    },
    {
        "question": "Statement 1| After mapped into feature space Q through a radial basis kernel function, 1-NN using unweighted Euclidean distance may be able to achieve better classification performance than in original space (though we can’t guarantee this). Statement 2| The VC dimension of a Perceptron is smaller than the VC dimension of a simple linear SVM.",
        "answer": 1,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Explain the concept of the radial basis kernel function and how it transforms data into feature space Q, highlighting the potential benefits of this transformation for 1-NN classification.",
        "instruction 2": "Compare the VC dimension of a Perceptron with that of a simple linear SVM, explaining the implications of this comparison for the generalization capabilities of each model."
    },
    {
        "question": "The disadvantage of Grid search is",
        "answer": 3,
        "choices": [
            "It can not be applied to non-differentiable functions.",
            "It can not be applied to non-continuous functions.",
            "It is hard to implement.",
            "It runs reasonably slow for multiple linear regression."
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the primary limitation of Grid search, such as its computational complexity, which can lead to slow convergence rates and increased computational costs.",
        "instruction 2": "Consider how this limitation can be mitigated by using alternative optimization techniques, such as gradient-based methods, or by employing parallel computing strategies to reduce computational time."
    },
    {
        "question": "Predicting the amount of rainfall in a region based on various cues is a ______ problem.",
        "answer": 0,
        "choices": [
            "Supervised learning",
            "Unsupervised learning",
            "Clustering",
            "None of the above"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the type of problem being described, such as a forecasting or prediction problem, and consider the factors that influence rainfall patterns, including weather patterns, climate trends, and geographic features.",
        "instruction 2": "Evaluate the role of machine learning or statistical models in predicting rainfall, considering the types of data used, the complexity of the relationships between variables, and the potential sources of error or uncertainty in the predictions."
    },
    {
        "question": "Which of the following sentence is FALSE regarding regression?",
        "answer": 3,
        "choices": [
            "It relates inputs to outputs.",
            "It is used for prediction.",
            "It may be used for interpretation.",
            "It discovers causal relationships"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key characteristics of regression analysis, including its purpose, types, and assumptions, to determine which sentence is not accurately describing a regression concept.",
        "instruction 2": "Evaluate the given sentences, considering the principles of regression analysis, such as the relationship between dependent and independent variables, and the importance of residuals and correlation coefficients, to identify the sentence that contradicts these principles."
    },
    {
        "question": "Which one of the following is the main reason for pruning a Decision Tree?",
        "answer": 3,
        "choices": [
            "To save computing time during testing",
            "To save space for storing the Decision Tree",
            "To make the training set error smaller",
            "To avoid overfitting the training set"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the primary purpose of pruning a decision tree, focusing on the reduction of overfitting, which occurs when the tree becomes too complex and overly specific to the training data.",
        "instruction 2": "Consider how pruning can help improve the model's generalizability and prevent it from becoming too sensitive to noise in the training data, ensuring that the resulting tree is more robust and accurate."
    },
    {
        "question": "Statement 1| The kernel density estimator is equivalent to performing kernel regression with the value Yi = 1/n at each point Xi in the original data set. Statement 2| The depth of a learned decision tree can be larger than the number of training examples used to create the tree.",
        "answer": 1,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Analyze the two statements to determine their accuracy; assess the properties of the kernel density estimator in relation to kernel regression, and evaluate the implications of decision tree depth relative to the number of training examples.",
        "instruction 2": "Identify the concepts of underfitting and overfitting in machine learning, considering how they relate to kernel methods and decision trees, and discuss how these concepts can influence model performance."
    },
    {
        "question": "Suppose your model is overfitting. Which of the following is NOT a valid way to try and reduce the overfitting?",
        "answer": 1,
        "choices": [
            "Increase the amount of training data.",
            "Improve the optimisation algorithm being used for error minimisation.",
            "Decrease the model complexity.",
            "Reduce the noise in the training data."
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify potential methods to address overfitting, such as regularization techniques (e.g., L1, L2), early stopping, and data augmentation.",
        "instruction 2": "Evaluate each method's effectiveness in reducing overfitting and eliminate any that are not valid or effective, ensuring to provide a clear justification for the elimination."
    },
    {
        "question": "Statement 1| The softmax function is commonly used in mutliclass logistic regression. Statement 2| The temperature of a nonuniform softmax distribution affects its entropy.",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Explain the purpose of the softmax function in multiclass logistic regression, highlighting its role in normalizing output probabilities.",
        "instruction 2": "Discuss the concept of entropy in the context of the softmax function, examining how the temperature parameter affects the distribution's entropy and its implications for model performance."
    },
    {
        "question": "Which of the following is/are true regarding an SVM?",
        "answer": 0,
        "choices": [
            "For two dimensional data points, the separating hyperplane learnt by a linear SVM will be a straight line.",
            "In theory, a Gaussian kernel SVM cannot model any complex separating hyperplane.",
            "For every kernel function used in a SVM, one can obtain an equivalent closed form basis expansion.",
            "Overfitting in an SVM is not a function of number of support vectors."
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key characteristics of Support Vector Machines (SVMs) that distinguish them from other machine learning algorithms, such as their use of a hyperplane to separate data and the ability to handle non-linearly separable data.",
        "instruction 2": "Consider the strengths and limitations of SVMs, including their ability to handle high-dimensional data, their sensitivity to the choice of kernel function, and their potential to be computationally expensive for large datasets."
    },
    {
        "question": "Which of the following is the joint probability of H, U, P, and W described by the given Bayesian Network H -> U <- P <- W? [note: as the product of the conditional probabilities]",
        "answer": 2,
        "choices": [
            "P(H, U, P, W) = P(H) * P(W) * P(P) * P(U)",
            "P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(W | H, P)",
            "P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)",
            "None of the above"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the nodes in the Bayesian Network and their relationships, specifically focusing on the conditional dependencies between H, U, P, and W.",
        "instruction 2": "Calculate the joint probability as the product of the conditional probabilities, using the network structure to determine the order of multiplication and ensuring to correctly account for the dependencies between the nodes."
    },
    {
        "question": "Statement 1| Since the VC dimension for an SVM with a Radial Base Kernel is infinite, such an SVM must be worse than an SVM with polynomial kernel which has a finite VC dimension. Statement 2| A two layer neural network with linear activation functions is essentially a weighted combination of linear separators, trained on a given dataset; the boosting algorithm built on linear separators also finds a combination of linear separators, therefore these two algorithms will give the same result.",
        "answer": 1,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key concept in Statement 1, which is the VC dimension and its implications on the performance of the SVM with different kernels.",
        "instruction 2": "Consider the relationship between the two statements, examining how the VC dimension affects the performance of the SVM and the relationship between the two-layer neural network and the boosting algorithm, and determine whether the statements are true or false."
    },
    {
        "question": "Statement 1| The ID3 algorithm is guaranteed to find the optimal decision tree. Statement 2| Consider a continuous probability distribution with density f() that is nonzero everywhere. The probability of a value x is equal to f(x).",
        "answer": 1,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Evaluate the claims made in each statement, identifying any assumptions or limitations that may be implicit in the statements.",
        "instruction 2": "Consider the conditions under which the ID3 algorithm might not find the optimal decision tree, and explore the implications of this for the reliability of the algorithm's outputs."
    },
    {
        "question": "Given a Neural Net with N input nodes, no hidden layers, one output node, with Entropy Loss and Sigmoid Activation Functions, which of the following algorithms (with the proper hyper-parameters and initialization) can be used to find the global optimum?",
        "answer": 3,
        "choices": [
            "Stochastic Gradient Descent",
            "Mini-Batch Gradient Descent",
            "Batch Gradient Descent",
            "All of the above"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the specific characteristics of the Neural Net, such as the absence of hidden layers, the use of Entropy Loss and Sigmoid Activation Functions, and the number of input and output nodes.",
        "instruction 2": "Research algorithms suitable for this type of Neural Net, considering factors such as optimization methods, initialization strategies, and hyper-parameters, to determine which algorithm can potentially find the global optimum."
    },
    {
        "question": "Adding more basis functions in a linear model, pick the most probably option:",
        "answer": 0,
        "choices": [
            "Decreases model bias",
            "Decreases estimation bias",
            "Decreases variance",
            "Doesn’t affect bias and variance"
        ],
        "subject": "machine_learning",
        "instruction 1": "Understand the concept of basis functions in linear regression and how they contribute to the model's ability to capture complex relationships between variables.",
        "instruction 2": "Explain how adding more basis functions can improve the model's fit to the data, potentially reducing the error term, and discuss the potential drawbacks, such as overfitting, that can arise from increasing the number of basis functions."
    },
    {
        "question": "Consider the Bayesian network given below. How many independent parameters would we need if we made no assumptions about independence or conditional independence H -> U <- P <- W?",
        "answer": 3,
        "choices": [
            "3",
            "4",
            "7",
            "15"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the variables in the Bayesian network and their relationships, including the conditional dependencies between them.",
        "instruction 2": "Calculate the number of independent parameters required to fully specify the network, taking into account the lack of assumptions about independence or conditional independence."
    },
    {
        "question": "Another term for out-of-distribution detection is?",
        "answer": 0,
        "choices": [
            "anomaly detection",
            "one-class detection",
            "train-test mismatch robustness",
            "background detection"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the concept of out-of-distribution detection in the context of machine learning and artificial intelligence, which involves identifying instances where input data falls outside the expected range or pattern.",
        "instruction 2": "Research alternative terms or phrases used to describe this concept, such as 'anomaly detection' or 'outlier detection', to provide a comprehensive answer."
    },
    {
        "question": "Statement 1| We learn a classifier f by boosting weak learners h. The functional form of f’s decision boundary is the same as h’s, but with different parameters. (e.g., if h was a linear classifier, then f is also a linear classifier). Statement 2| Cross validation can be used to select the number of iterations in boosting; this procedure may help reduce overfitting.",
        "answer": 3,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key components of the boosting process, focusing on the role of weak learners and how they contribute to the creation of a strong classifier.",
        "instruction 2": "Consider the relationship between cross-validation and the selection of the number of iterations in boosting, exploring how this procedure can help mitigate overfitting and improve model performance."
    },
    {
        "question": "Statement 1| Highway networks were introduced after ResNets and eschew max pooling in favor of convolutions. Statement 2| DenseNets usually cost more memory than ResNets.",
        "answer": 3,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key differences between Highway Networks and Residual Networks, focusing on the use of max pooling and convolutions in each architecture.",
        "instruction 2": "Compare the memory requirements of DenseNets and ResNets, considering how the increased number of connections in DenseNets affects memory usage and potential trade-offs."
    },
    {
        "question": "If N is the number of instances in the training dataset, nearest neighbors has a classification run time of",
        "answer": 1,
        "choices": [
            "O(1)",
            "O( N )",
            "O(log N )",
            "O( N^2 )"
        ],
        "subject": "machine_learning",
        "instruction 1": "Understand the basic concept of the nearest neighbors algorithm, focusing on its reliance on calculating distances between instances in the training dataset.",
        "instruction 2": "Consider the computational complexity of the algorithm, recognizing that the time complexity is directly related to the number of instances in the training dataset (N), and the number of distances that need to be calculated."
    },
    {
        "question": "Statement 1| The original ResNets and Transformers are feedforward neural networks. Statement 2| The original Transformers use self-attention, but the original ResNet does not.",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key architectural components of the original ResNets and Transformers, focusing on their feedforward nature and the presence or absence of self-attention mechanisms.",
        "instruction 2": "Consider the implications of these architectural differences on the performance and applications of the original ResNets and Transformers, highlighting any unique strengths or limitations of each model."
    },
    {
        "question": "Statement 1| RELUs are not monotonic, but sigmoids are monotonic. Statement 2| Neural networks trained with gradient descent with high probability converge to the global optimum.",
        "answer": 3,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Explain the differences between RELUs (Rectified Linear Units) and sigmoids, highlighting their respective properties, such as the lack of monotonicity in RELUs and the monotonicity in sigmoids.",
        "instruction 2": "Discuss the relationship between the convergence of neural networks trained with gradient descent and the probability of reaching the global optimum, considering factors such as the choice of activation function, optimization algorithm, and initial conditions."
    },
    {
        "question": "The numerical output of a sigmoid node in a neural network:",
        "answer": 2,
        "choices": [
            "Is unbounded, encompassing all real numbers.",
            "Is unbounded, encompassing all integers.",
            "Is bounded between 0 and 1.",
            "Is bounded between -1 and 1."
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key function of a sigmoid node in a neural network, which is to introduce non-linearity to the model by mapping the input to a value between 0 and 1.",
        "instruction 2": "Consider how the sigmoid function is often used in binary classification problems, where the output represents the probability of the input belonging to a specific class, and how this output is used in the decision-making process."
    },
    {
        "question": "Which of the following can only be used when training data are linearly separable?",
        "answer": 0,
        "choices": [
            "Linear hard-margin SVM.",
            "Linear Logistic Regression.",
            "Linear Soft margin SVM.",
            "The centroid method."
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the type of machine learning algorithm that is commonly used for binary classification problems where the data is linearly separable, such as logistic regression or support vector machines.",
        "instruction 2": "Consider the limitations of these algorithms, specifically how they require the data to be linearly separable, and how this constraint affects the model's ability to accurately classify non-linearly separable data."
    },
    {
        "question": "Which of the following are the spatial clustering algorithms?",
        "answer": 3,
        "choices": [
            "Partitioning based clustering",
            "K-means clustering",
            "Grid based clustering",
            "All of the above"
        ],
        "subject": "machine_learning",
        "instruction 1": "Research and identify spatial clustering algorithms, focusing on their ability to group similar spatial data points or objects together based on their proximity and other relevant characteristics.",
        "instruction 2": "Consider the key differences and trade-offs between various spatial clustering algorithms, such as k-means, DBSCAN, and hierarchical clustering, and evaluate their suitability for different applications and data types."
    },
    {
        "question": "Statement 1| The maximum margin decision boundaries that support vector machines construct have the lowest generalization error among all linear classifiers. Statement 2| Any decision boundary that we get from a generative model with classconditional Gaussian distributions could in principle be reproduced with an SVM and a polynomial kernel of degree less than or equal to three.",
        "answer": 3,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key claims made in each statement, focusing on the relationship between support vector machines, generalization error, and decision boundaries.",
        "instruction 2": "Consider the implications of each statement, evaluating the strengths and limitations of support vector machines and generative models in terms of decision boundary construction and reproduction."
    },
    {
        "question": "Statement 1| L2 regularization of linear models tends to make models more sparse than L1 regularization. Statement 2| Residual connections can be found in ResNets and Transformers.",
        "answer": 3,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key differences between L1 and L2 regularization in linear models, focusing on the effects on model sparsity and feature selection.",
        "instruction 2": "Consider the role of residual connections in neural networks, such as ResNets and Transformers, and how they enable the flow of information between different layers and improve model performance."
    },
    {
        "question": "Suppose we like to calculate P(H|E, F) and we have no conditional independence information. Which of the following sets of numbers are sufficient for the calculation?",
        "answer": 1,
        "choices": [
            "P(E, F), P(H), P(E|H), P(F|H)",
            "P(E, F), P(H), P(E, F|H)",
            "P(H), P(E|H), P(F|H)",
            "P(E, F), P(E|H), P(F|H)"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the relevant probability values needed for the calculation, including the prior probability P(H), the likelihood P(E|H), and the likelihood P(F|H), as well as any relevant conditional probability values.",
        "instruction 2": "Determine if any additional information, such as conditional independence relationships, is required to calculate P(H|E, F), and if not, identify the specific probability values necessary for the calculation."
    },
    {
        "question": "Which among the following prevents overfitting when we perform bagging?",
        "answer": 1,
        "choices": [
            "The use of sampling with replacement as the sampling technique",
            "The use of weak classifiers",
            "The use of classification algorithms which are not prone to overfitting",
            "The practice of validation performed on every classifier trained"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the primary mechanism by which bagging helps prevent overfitting, such as reducing variance and increasing the robustness of the model through ensemble averaging.",
        "instruction 2": "Consider how the combination of multiple models, each trained on a subset of the data, can reduce overfitting by averaging out the noise and improving the overall generalizability of the model."
    },
    {
        "question": "Statement 1| PCA and Spectral Clustering (such as Andrew Ng’s) perform eigendecomposition on two different matrices. However, the size of these two matrices are the same. Statement 2| Since classification is a special case of regression, logistic regression is a special case of linear regression.",
        "answer": 1,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Determine the specific differences in the eigendecomposition process between PCA and Spectral Clustering, highlighting the distinct matrices used in each method.",
        "instruction 2": "Analyze the relationship between classification and regression, explaining why logistic regression is a special case of linear regression and how this impacts the classification problem."
    },
    {
        "question": "Statement 1| The Stanford Sentiment Treebank contained movie reviews, not book reviews. Statement 2| The Penn Treebank has been used for language modeling.",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the specific datasets mentioned in the statements, including the Stanford Sentiment Treebank and the Penn Treebank, and note their respective focuses on movie reviews and language modeling.",
        "instruction 2": "Consider the implications of these statements, such as the potential applications of the Stanford Sentiment Treebank for sentiment analysis in the film industry and the use of the Penn Treebank for language modeling tasks."
    },
    {
        "question": "What is the dimensionality of the null space of the following matrix? A = [[3, 2, −9], [−6, −4, 18], [12, 8, −36]]",
        "answer": 2,
        "choices": [
            "0",
            "1",
            "2",
            "3"
        ],
        "subject": "machine_learning",
        "instruction 1": "Determine the rank of the matrix A by calculating the determinant and/or using the row echelon form to identify the number of linearly independent rows.",
        "instruction 2": "Use the rank-nullity theorem to determine the dimensionality of the null space, which is equal to the difference between the number of columns and the rank of the matrix."
    },
    {
        "question": "What are support vectors?",
        "answer": 1,
        "choices": [
            "The examples farthest from the decision boundary.",
            "The only examples necessary to compute f(x) in an SVM.",
            "The data centroid.",
            "All the examples that have a non-zero weight αk in a SVM."
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the primary purpose of support vectors in a support vector machine (SVM), which is to separate data points into distinct classes or categories.",
        "instruction 2": "Explain how the distance between the support vectors and the hyperplane, as well as the margin between the classes, contribute to the overall performance and accuracy of the SVM model."
    },
    {
        "question": "Statement 1| Word2Vec parameters were not initialized using a Restricted Boltzman Machine. Statement 2| The tanh function is a nonlinear activation function.",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the specific components or techniques used in the Word2Vec model, such as the initialization of parameters and the activation function, to better understand the architecture and functionality of the model.",
        "instruction 2": "Consider the implications of using the tanh function as an activation function in the Word2Vec model, evaluating its potential effects on the model's performance, particularly in terms of capturing semantic relationships between words."
    },
    {
        "question": "If your training loss increases with number of epochs, which of the following could be a possible issue with the learning process?",
        "answer": 2,
        "choices": [
            "Regularization is too low and model is overfitting",
            "Regularization is too high and model is underfitting",
            "Step size is too large",
            "Step size is too small"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify common reasons why the training loss might increase with the number of epochs, such as overfitting, underfitting, or an imbalanced dataset.",
        "instruction 2": "Consider potential solutions to address the issue, such as adjusting the model architecture, regularization techniques, or data augmentation strategies, and evaluate their effectiveness in improving the learning process."
    },
    {
        "question": "Say the incidence of a disease D is about 5 cases per 100 people (i.e., P(D) = 0.05). Let Boolean random variable D mean a patient “has disease D” and let Boolean random variable TP stand for \"tests positive.\" Tests for disease D are known to be very accurate in the sense that the probability of testing positive when you have the disease is 0.99, and the probability of testing negative when you do not have the disease is 0.97. What is P(D | TP), the posterior probability that you have disease D when the test is positive?",
        "answer": 2,
        "choices": [
            "0.0495",
            "0.078",
            "0.635",
            "0.97"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the given information about the accuracy of the test, including the probability of testing positive when having the disease and the probability of testing negative when not having the disease.",
        "instruction 2": "Use Bayes' theorem to calculate the posterior probability P(D | TP) by updating the prior probability P(D) with the likelihood of testing positive given the presence of the disease, taking into account the test's accuracy."
    },
    {
        "question": "Statement 1| Traditional machine learning results assume that the train and test sets are independent and identically distributed. Statement 2| In 2017, COCO models were usually pretrained on ImageNet.",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key assumption underlying traditional machine learning, focusing on the independence and identically distributed nature of the training and testing data.",
        "instruction 2": "Consider how this assumption may be challenged in real-world scenarios, such as when there is a significant overlap between the training and testing data, and how this can impact the performance of machine learning models, referencing COCO models and ImageNet as examples."
    },
    {
        "question": "Statement 1| The values of the margins obtained by two different kernels K1(x, x0) and K2(x, x0) on the same training set do not tell us which classifier will perform better on the test set. Statement 2| The activation function of BERT is the GELU.",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key concepts involved in the statements, including the role of kernels, margins, and training sets in machine learning, as well as the concept of activation functions in neural networks.",
        "instruction 2": "Consider the implications of the statements, evaluating the limitations of using margin values to predict test set performance and the significance of the GELU activation function in BERT's architecture.\" }\n\nPlease provide the reasoning steps and implicit constraints for the given question. Your response should be in plain text JSON format, with the “key” being the instruct number and the “value” including the specific associated instructions. Your response must include two new instructions. \n\nQuestion: What is the volume of the solid in xyz-space bounded by the surfaces y = x^2, y = 2 - x^2, z = 0, and z = y + 3? \n\nPlease provide your response in the following format:\n\n{\n\"instruction 1\": \"Your instruction 1 text"
    },
    {
        "question": "Which of the following is a clustering algorithm in machine learning?",
        "answer": 0,
        "choices": [
            "Expectation Maximization",
            "CART",
            "Gaussian Naïve Bayes",
            "Apriori"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify and analyze the list of algorithms provided, distinguishing between clustering algorithms and other types of algorithms such as classification or regression, focusing on their core functions and methodologies.",
        "instruction 2": "Review common examples of clustering algorithms, such as K-means, hierarchical clustering, and DBSCAN, to provide insight into their characteristics and how they differ from non-clustering algorithms."
    },
    {
        "question": "You've just finished training a decision tree for spam classification, and it is getting abnormally bad performance on both your training and test sets. You know that your implementation has no bugs, so what could be causing the problem?",
        "answer": 0,
        "choices": [
            "Your decision trees are too shallow.",
            "You need to increase the learning rate.",
            "You are overfitting.",
            "None of the above."
        ],
        "subject": "machine_learning",
        "instruction 1": "Consider the potential sources of overfitting, such as the tree's complexity, the number of features used, or the size of the training set, and evaluate whether these factors might be contributing to the poor performance.",
        "instruction 2": "Investigate whether there are any issues with the data itself, such as class imbalance, noisy or missing values, or feature correlations, that could be affecting the model's ability to generalize and perform well on new, unseen data."
    },
    {
        "question": "K-fold cross-validation is",
        "answer": 0,
        "choices": [
            "linear in K",
            "quadratic in K",
            "cubic in K",
            "exponential in K"
        ],
        "subject": "machine_learning",
        "instruction 1": "Understand the fundamental concept of K-fold cross-validation, which involves dividing the dataset into K subsets, training the model on K-1 subsets, and evaluating its performance on the remaining subset.",
        "instruction 2": "Consider how K-fold cross-validation addresses issues such as overfitting and provides a more accurate estimate of a model's generalizability by using multiple subsets to evaluate performance, rather than relying on a single training-testing split."
    },
    {
        "question": "Statement 1| Industrial-scale neural networks are normally trained on CPUs, not GPUs. Statement 2| The ResNet-50 model has over 1 billion parameters.",
        "answer": 1,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Evaluate the feasibility of training industrial-scale neural networks on CPUs, considering factors such as processing power, memory constraints, and computational efficiency.",
        "instruction 2": "Analyze the implications of having over 1 billion parameters in the ResNet-50 model, examining how this may impact training time, memory requirements, and the overall performance of the network."
    },
    {
        "question": "Given two Boolean random variables, A and B, where P(A) = 1/2, P(B) = 1/3, and P(A | ¬B) = 1/4, what is P(A | B)?",
        "answer": 3,
        "choices": [
            "1/6",
            "1/4",
            "3/4",
            "1"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the given conditional probability, P(A | ¬B), and recognize that it represents the probability of A given the negation of B.",
        "instruction 2": "Use Bayes' theorem to derive the conditional probability P(A | B) by applying the given probabilities and the negation of B, ensuring to account for the independence of A and B given ¬B."
    },
    {
        "question": "Existential risks posed by AI are most commonly associated with which of the following professors?",
        "answer": 2,
        "choices": [
            "Nando de Frietas",
            "Yann LeCun",
            "Stuart Russell",
            "Jitendra Malik"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key figures in the field of AI and existential risk, such as professors who have written extensively on the topic, and their associated theories or warnings.",
        "instruction 2": "Consider the specific arguments and concerns raised by these professors, such as Nick Bostrom, Elon Musk, or Stephen Hawking, regarding the potential dangers of advanced artificial intelligence and the need for caution and regulation."
    },
    {
        "question": "Statement 1| Maximizing the likelihood of logistic regression model yields multiple local optimums. Statement 2| No classifier can do better than a naive Bayes classifier if the distribution of the data is known.",
        "answer": 1,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Understand the implications of Statement 1, which suggests that the optimization process in logistic regression may not always converge to the global optimum, and consider the potential consequences for model performance.",
        "instruction 2": "Evaluate the conditions under which Statement 2 is true, such as the assumption of known data distribution, and explore the limitations of the naive Bayes classifier in these situations."
    },
    {
        "question": "For Kernel Regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:",
        "answer": 2,
        "choices": [
            "Whether kernel function is Gaussian versus triangular versus box-shaped",
            "Whether we use Euclidian versus L1 versus L∞ metrics",
            "The kernel width",
            "The maximum height of the kernel function"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the structural assumption in Kernel Regression that is most critical in determining the trade-off between underfitting and overfitting, such as the choice of kernel function or the regularization parameter.",
        "instruction 2": "Explain how this assumption affects the model's ability to balance between fitting the training data too closely (overfitting) and failing to capture the underlying pattern (underfitting), highlighting the implications for model selection and tuning."
    },
    {
        "question": "Statement 1| The SVM learning algorithm is guaranteed to find the globally optimal hypothesis with respect to its object function. Statement 2| After being mapped into feature space Q through a radial basis kernel function, a Perceptron may be able to achieve better classification performance than in its original space (though we can’t guarantee this).",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key differences in the statements, focusing on the guarantees and limitations of the SVM and Perceptron algorithms, particularly with respect to their respective object functions and performance.",
        "instruction 2": "Consider how the use of kernel functions, such as radial basis functions, can affect the performance of the Perceptron algorithm, and how this compares to the guaranteed performance of the SVM algorithm."
    },
    {
        "question": "For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:",
        "answer": 1,
        "choices": [
            "Whether we learn the class centers by Maximum Likelihood or Gradient Descent",
            "Whether we assume full class covariance matrices or diagonal class covariance matrices",
            "Whether we have equal class priors or priors estimated from the data.",
            "Whether we allow classes to have different mean vectors or we force them to share the same mean vector"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key structural assumption in a Gaussian Bayes classifier that influences the trade-off between underfitting and overfitting, such as the assumption of a normal distribution for the features.",
        "instruction 2": "Consider how this assumption affects the classifier's ability to balance between fitting the training data too closely (overfitting) and failing to capture the underlying patterns (underfitting), and how this trade-off is managed through regularization techniques."
    },
    {
        "question": "Statement 1| Overfitting is more likely when the set of training data is small. Statement 2| Overfitting is more likely when the hypothesis space is small.",
        "answer": 3,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Analyze the relationship between the size of the training data and the likelihood of overfitting, considering how a smaller dataset may lead to an overfitting issue due to the limited information available for model training.",
        "instruction 2": "Examine the connection between the size of the hypothesis space and the likelihood of overfitting, discussing how a smaller hypothesis space may reduce the risk of overfitting by limiting the number of possible solutions."
    },
    {
        "question": "Statement 1| Besides EM, gradient descent can be used to perform inference or learning on Gaussian mixture model. Statement 2 | Assuming a fixed number of attributes, a Gaussian-based Bayes optimal classifier can be learned in time linear in the number of records in the dataset.",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the connection between the statements, focusing on the shared concept of Gaussian mixture models and their relationship to gradient descent and Bayes optimal classification.",
        "instruction 2": "Consider how the statements relate to each other in terms of the learning and inference capabilities of Gaussian mixture models, exploring the implications of combining these concepts for real-world applications."
    },
    {
        "question": "Statement 1| In a Bayesian network, the inference results of the junction tree algorithm are the same as the inference results of variable elimination. Statement 2| If two random variable X and Y are conditionally independent given another random variable Z, then in the corresponding Bayesian network, the nodes for X and Y are d-separated given Z.",
        "answer": 2,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Explain the underlying principles of Bayesian networks and the role of junction trees and variable elimination in inference, highlighting any potential differences or similarities between the two algorithms.",
        "instruction 2": "Illustrate the concept of conditional independence and d-separation in Bayesian networks, using the given statement as a starting point, and discussing how these concepts relate to the structure and inference of the network."
    },
    {
        "question": "Given a large dataset of medical records from patients suffering from heart disease, try to learn whether there might be different clusters of such patients for which we might tailor separate treatments. What kind of learning problem is this?",
        "answer": 1,
        "choices": [
            "Supervised learning",
            "Unsupervised learning",
            "Both (a) and (b)",
            "Neither (a) nor (b)"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the type of data being analyzed (medical records) and the goal of the analysis (clustering patients for tailored treatments).",
        "instruction 2": "Determine the specific clustering algorithm and evaluation metrics that would be suitable for this problem, considering factors such as data dimensionality, noise, and the need for interpretable results."
    },
    {
        "question": "What would you do in PCA to get the same projection as SVD?",
        "answer": 0,
        "choices": [
            "Transform data to zero mean",
            "Transform data to zero median",
            "Not possible",
            "None of these"
        ],
        "subject": "machine_learning",
        "instruction 1": "Recall the mathematical relationship between Principal Component Analysis (PCA) and Singular Value Decomposition (SVD), highlighting the connection between the eigenvectors and singular vectors.",
        "instruction 2": "Demonstrate how to modify the PCA algorithm to obtain the same projection as SVD by using the eigenvectors and eigenvalues to construct the orthonormal basis, and then applying the transformation to the data."
    },
    {
        "question": "Statement 1| The training error of 1-nearest neighbor classifier is 0. Statement 2| As the number of data points grows to infinity, the MAP estimate approaches the MLE estimate for all possible priors. In other words, given enough data, the choice of prior is irrelevant.",
        "answer": 2,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key assumptions and conditions necessary for Statement 1 to hold true, such as the specific 1-nearest neighbor classifier being used and the nature of the training data.",
        "instruction 2": "Consider the implications of Statement 2, examining how the MAP estimate and MLE estimate converge as the number of data points increases, and evaluating the significance of prior choice in the context of this convergence."
    },
    {
        "question": "When doing least-squares regression with regularisation (assuming that the optimisation can be done exactly), increasing the value of the regularisation parameter λ the testing error.",
        "answer": 0,
        "choices": [
            "will never decrease the training error.",
            "will never increase the training error.",
            "will never decrease the testing error.",
            "will never increase"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the relationship between the regularisation parameter λ and the testing error in the context of least-squares regression, considering how the parameter affects the model's complexity and overfitting.",
        "instruction 2": "Consider how the optimisation process, assuming it can be done exactly, influences the relationship between λ and the testing error, taking into account the trade-off between model complexity and generalisation performance."
    },
    {
        "question": "Which of the following best describes what discriminative approaches try to model? (w are the parameters in the model)",
        "answer": 0,
        "choices": [
            "p(y|x, w)",
            "p(y, x)",
            "p(w|x, w)",
            "None of the above"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the primary goal of discriminative approaches, which is to model the probability of a specific class or label given the input features, as opposed to generative approaches that model the probability of the input given the class.",
        "instruction 2": "Consider how the parameters w in the model are used to learn the mapping between the input features and the corresponding class labels, and how this mapping is optimized to minimize the error or maximize the accuracy of the model."
    },
    {
        "question": "Statement 1| CIFAR-10 classification performance for convolution neural networks can exceed 95%. Statement 2| Ensembles of neural networks do not improve classification accuracy since the representations they learn are highly correlated.",
        "answer": 2,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key claims made in each statement, focusing on the performance of convolutional neural networks in CIFAR-10 classification and the effectiveness of ensembles in improving classification accuracy.",
        "instruction 2": "Consider the potential implications of each statement, evaluating the potential benefits and limitations of using ensembles in conjunction with convolutional neural networks for CIFAR-10 classification, and the potential correlations between the representations learned by individual networks."
    },
    {
        "question": "Which of the following points would Bayesians and frequentists disagree on?",
        "answer": 2,
        "choices": [
            "The use of a non-Gaussian noise model in probabilistic regression.",
            "The use of probabilistic modelling for regression.",
            "The use of prior distributions on the parameters in a probabilistic model.",
            "The use of class priors in Gaussian Discriminant Analysis."
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key differences between Bayesian and frequentist statistical approaches, focusing on their distinct perspectives on probability, inference, and the role of prior knowledge.",
        "instruction 2": "Consider specific points of contention between the two schools of thought, such as the use of prior distributions, the interpretation of p-values, and the role of subjective judgment in statistical analysis."
    },
    {
        "question": "Statement 1| The BLEU metric uses precision, while the ROGUE metric uses recall. Statement 2| Hidden markov models were frequently used to model English sentences.",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Determine the specific criteria used by each metric (BLEU and ROGUE) to evaluate machine translation quality, focusing on the differences in their evaluation approaches.",
        "instruction 2": "Explain the role of hidden Markov models in natural language processing, specifically in modeling English sentences, and how they have been used in the past to improve machine translation systems."
    },
    {
        "question": "Statement 1| ImageNet has images of various resolutions. Statement 2| Caltech-101 has more images than ImageNet.",
        "answer": 2,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Determine the resolution of images in the ImageNet dataset, as mentioned in Statement 1.",
        "instruction 2": "Compare the number of images in the Caltech-101 dataset with the number of images in the ImageNet dataset, evaluating whether Statement 2 is true or false based on the provided information."
    },
    {
        "question": "Which of the following is more appropriate to do feature selection?",
        "answer": 1,
        "choices": [
            "Ridge",
            "Lasso",
            "both (a) and (b)",
            "neither (a) nor (b)"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key differences between filter and wrapper methods for feature selection, considering the trade-offs between computational efficiency, interpretability, and model performance.",
        "instruction 2": "Evaluate the suitability of each method for the specific problem or dataset at hand, taking into account factors such as the number of features, the complexity of the model, and the availability of computational resources."
    },
    {
        "question": "Suppose you are given an EM algorithm that finds maximum likelihood estimates for a model with latent variables. You are asked to modify the algorithm so that it finds MAP estimates instead. Which step or steps do you need to modify?",
        "answer": 1,
        "choices": [
            "Expectation",
            "Maximization",
            "No modification necessary",
            "Both"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key differences between maximum likelihood estimation and maximum a posteriori (MAP) estimation, focusing on the role of prior distributions in MAP estimation.",
        "instruction 2": "Determine which components of the EM algorithm, such as the E-step or M-step, need to be modified to incorporate prior information and integrate it into the MAP estimation process."
    },
    {
        "question": "For a Gaussian Bayes classifier, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting:",
        "answer": 1,
        "choices": [
            "Whether we learn the class centers by Maximum Likelihood or Gradient Descent",
            "Whether we assume full class covariance matrices or diagonal class covariance matrices",
            "Whether we have equal class priors or priors estimated from the data",
            "Whether we allow classes to have different mean vectors or we force them to share the same mean vector"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key structural assumptions underlying the Gaussian Bayes classifier, such as the normality of the features and the class-conditional distributions.",
        "instruction 2": "Examine how these assumptions influence the trade-off between underfitting and overfitting, highlighting which assumption has the most significant impact on the classifier's performance in terms of bias-variance tradeoff."
    },
    {
        "question": "Statement 1| For any two variables x and y having joint distribution p(x, y), we always have H[x, y] ≥ H[x] + H[y] where H is entropy function. Statement 2| For some directed graphs, moralization decreases the number of edges present in the graph.",
        "answer": 1,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Understand the context of the statements, focusing on the concept of entropy and its relationship to joint distributions and marginal distributions, as well as the concept of moralization in directed graphs.",
        "instruction 2": "Analyze the implications of the statements, considering how the relationships between entropy, joint distributions, and marginal distributions might be affected by moralization, and how this could impact the number of edges in a directed graph."
    },
    {
        "question": "Which of the following is NOT supervised learning?",
        "answer": 0,
        "choices": [
            "PCA",
            "Decision Tree",
            "Linear Regression",
            "Naive Bayesian"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key characteristics of supervised learning, such as the presence of labeled training data, a clear target variable, and the goal of making accurate predictions.",
        "instruction 2": "Consider the given options and determine which one does not fit the definition of supervised learning, potentially due to the absence of labeled data or a different learning objective."
    },
    {
        "question": "Statement 1| A neural network's convergence depends on the learning rate. Statement 2| Dropout multiplies randomly chosen activation values by zero.",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Understand the role of the learning rate in neural network training, including how it affects convergence and potential pitfalls such as overshooting or undershooting.",
        "instruction 2": "Explain the purpose and mechanics of dropout regularization, highlighting how it helps prevent overfitting by randomly eliminating neurons during training and reducing the model's reliance on specific features."
    },
    {
        "question": "Which one of the following is equal to P(A, B, C) given Boolean random variables A, B and C, and no independence or conditional independence assumptions between any of them?",
        "answer": 2,
        "choices": [
            "P(A | B) * P(B | C) * P(C | A)",
            "P(C | A, B) * P(A) * P(B)",
            "P(A, B | C) * P(C)",
            "P(A | B, C) * P(B | A, C) * P(C | A, B)"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the formula for the probability of the intersection of three Boolean random variables, P(A, B, C), considering the lack of independence or conditional independence assumptions between A, B, and C.",
        "instruction 2": "Determine the correct mathematical expression for P(A, B, C) using the fundamental principles of probability theory, specifically the formula for the probability of the intersection of multiple events."
    },
    {
        "question": "Which of the following tasks can be best solved using Clustering.",
        "answer": 1,
        "choices": [
            "Predicting the amount of rainfall based on various cues",
            "Detecting fraudulent credit card transactions",
            "Training a robot to solve a maze",
            "All of the above"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the primary goals of clustering, such as grouping similar data points or identifying patterns, and determine how these objectives align with the given task.",
        "instruction 2": "Consider the characteristics of the task, such as the type of data involved and the desired outcome, to determine if clustering is a suitable approach for solving the problem."
    },
    {
        "question": "After applying a regularization penalty in linear regression, you find that some of the coefficients of w are zeroed out. Which of the following penalties might have been used?",
        "answer": 3,
        "choices": [
            "L0 norm",
            "L1 norm",
            "L2 norm",
            "either (a) or (b)"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the common penalties used in linear regression, such as L1 (Lasso) and L2 (Ridge) regularization, and consider their effects on the model coefficients.",
        "instruction 2": "Analyze the scenario where some coefficients are zeroed out, and determine which penalty type is most likely to cause this outcome, taking into account the characteristics of the penalty and the model's behavior."
    },
    {
        "question": "A and B are two events. If P(A, B) decreases while P(A) increases, which of the following is true?",
        "answer": 1,
        "choices": [
            "P(A|B) decreases",
            "P(B|A) decreases",
            "P(B) decreases",
            "All of above"
        ],
        "subject": "machine_learning",
        "instruction 1": "Determine the relationship between the probability of event A (P(A)) and the probability of event B (P(B)) using the formula P(A, B) = P(A) \\* P(B|A), where P(B|A) is the conditional probability of event B given event A.",
        "instruction 2": "Analyze the given information and determine whether the probability of event A (P(A)) increasing while the probability of event A and event B (P(A, B)) decreasing is consistent with the conditional probability formula, leading to an inference about the probability of event B (P(B))."
    },
    {
        "question": "Statement 1| When learning an HMM for a fixed set of observations, assume we do not know the true number of hidden states (which is often the case), we can always increase the training data likelihood by permitting more hidden states. Statement 2| Collaborative filtering is often a useful model for modeling users' movie preference.",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Examine the relationship between the number of hidden states in an HMM and the training data likelihood, considering how increasing the number of hidden states can improve the model's fit to the data.",
        "instruction 2": "Evaluate the suitability of collaborative filtering as a model for predicting users' movie preferences, taking into account the strengths and limitations of this approach compared to other methods, such as content-based filtering or matrix factorization."
    },
    {
        "question": "You are training a linear regression model for a simple estimation task, and notice that the model is overfitting to the data. You decide to add in $\\ell_2$ regularization to penalize the weights. As you increase the $\\ell_2$ regularization coefficient, what will happen to the bias and variance of the model?",
        "answer": 1,
        "choices": [
            "Bias increase ; Variance increase",
            "Bias increase ; Variance decrease",
            "Bias decrease ; Variance increase",
            "Bias decrease ; Variance decrease"
        ],
        "subject": "machine_learning",
        "instruction 1": "Understand how $\\ell_2$ regularization affects the model's weights, specifically how it introduces a penalty term to the loss function that encourages smaller weights.",
        "instruction 2": "Analyze how this penalty term influences the bias and variance of the model as the $\\ell_2$ regularization coefficient increases, considering how it affects the model's ability to capture complex patterns in the data and its tendency to overfit."
    },
    {
        "question": "Which PyTorch 1.8 command(s) produce $10\\times 5$ Gaussian matrix with each entry i.i.d. sampled from $\\mathcal{N}(\\mu=5,\\sigma^2=16)$ and a $10\\times 10$ uniform matrix with each entry i.i.d. sampled from $U[-1,1)$?",
        "answer": 2,
        "choices": [
            "\\texttt{5 + torch.randn(10,5) * 16} ; \\texttt{torch.rand(10,10,low=-1,high=1)}",
            "\\texttt{5 + torch.randn(10,5) * 16} ; \\texttt{(torch.rand(10,10) - 0.5) / 0.5}",
            "\\texttt{5 + torch.randn(10,5) * 4} ; \\texttt{2 * torch.rand(10,10) - 1}",
            "\\texttt{torch.normal(torch.ones(10,5)*5,torch.ones(5,5)*16)} ; \\texttt{2 * torch.rand(10,10) - 1}"
        ],
        "subject": "machine_learning",
        "instruction 1": "Determine the necessary PyTorch commands to generate the specified Gaussian and uniform matrices, focusing on the specific distributions and parameters provided.",
        "instruction 2": "Verify the generated matrices meet the required specifications by inspecting the output, ensuring that the Gaussian matrix has the correct size, distribution, and parameters, and the uniform matrix has the correct size and distribution."
    },
    {
        "question": "Statement 1| The ReLU's gradient is zero for $x<0$, and the sigmoid gradient $\\sigma(x)(1-\\sigma(x))\\le \\frac{1}{4}$ for all $x$. Statement 2| The sigmoid has a continuous gradient and the ReLU has a discontinuous gradient.",
        "answer": 0,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Compare the properties of the sigmoid and ReLU activation functions, focusing on their gradients and any discontinuities or singularities.",
        "instruction 2": "Evaluate the implications of these differences in gradient properties on the training and optimization of neural networks, considering how the choice of activation function may affect the model's performance and stability."
    },
    {
        "question": "Which is true about Batch Normalization?",
        "answer": 1,
        "choices": [
            "After applying batch normalization, the layer’s activations will follow a standard Gaussian distribution.",
            "The bias parameter of affine layers becomes redundant if a batch normalization layer follows immediately afterward.",
            "The standard weight initialization must be changed when using Batch Normalization.",
            "Batch Normalization is equivalent to Layer Normalization for convolutional neural networks."
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the primary purpose of Batch Normalization in deep learning, which is to normalize the input data to improve the stability and speed of training, and to reduce internal covariate shift.",
        "instruction 2": "Consider how Batch Normalization is typically implemented, such as by subtracting the mean and dividing by the standard deviation of the input data, and how this affects the model's performance and robustness."
    },
    {
        "question": "Suppose we have the following objective function: $\\argmin_{w} \\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\gamma \\norm{w}^2_2$ What is the gradient of $\\frac{1}{2} \\norm{Xw-y}^2_2 + \\frac{1}{2}\\lambda \\norm{w}^2_2$ with respect to $w$?",
        "answer": 2,
        "choices": [
            "$\\nabla_w f(w) = (X^\\top X + \\lambda I)w - X^\\top y + \\lambda w$",
            "$\\nabla_w f(w) = X^\\top X w - X^\\top y + \\lambda$",
            "$\\nabla_w f(w) = X^\\top X w - X^\\top y + \\lambda w$",
            "$\\nabla_w f(w) = X^\\top X w - X^\\top y + (\\lambda+1) w$"
        ],
        "subject": "machine_learning",
        "instruction 1": "Rewrite the objective function to separate the two terms, recognizing that the first term is a quadratic function of $w$ and the second term is a regularization term.",
        "instruction 2": "Compute the partial derivative of each term with respect to $w$, using the chain rule and properties of matrix operations, and combine the results to obtain the gradient of the objective function."
    },
    {
        "question": "Which of the following is true of a convolution kernel?",
        "answer": 1,
        "choices": [
            "Convolving an image with $\\begin{bmatrix}1 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$ would not change the image",
            "Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image",
            "Convolving an image with $\\begin{bmatrix}1 & 1 & 1\\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}$ would not change the image",
            "Convolving an image with $\\begin{bmatrix}0 & 0 & 0\\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{bmatrix}$ would not change the image"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key characteristics of a convolution kernel, such as its role in filtering or blurring data, and its ability to capture local patterns or features.",
        "instruction 2": "Consider the mathematical representation of a convolution kernel, including its definition as a function or matrix, and how it is used in various applications, such as image processing or signal processing, to transform or extract information from data."
    },
    {
        "question": "Which of the following is false?",
        "answer": 3,
        "choices": [
            "Semantic segmentation models predict the class of each pixel, while multiclass image classifiers predict the class of entire image.",
            "A bounding box with an IoU (intersection over union) equal to $96\\%$ would likely be considered at true positive.",
            "When a predicted bounding box does not correspond to any object in the scene, it is considered a false positive.",
            "A bounding box with an IoU (intersection over union) equal to $3\\%$ would likely be considered at false negative."
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the statements provided, and separate them into true and false categories based on your understanding of the topic or information.",
        "instruction 2": "Carefully evaluate each statement, considering any relevant evidence or context, to determine which one is false and provide a clear explanation for your answer."
    },
    {
        "question": "Which of the following is false?",
        "answer": 2,
        "choices": [
            "The following fully connected network without activation functions is linear: $g_3(g_2(g_1(x)))$, where $g_i(x) = W_i x$ and $W_i$ are matrices.",
            "Leaky ReLU $\\max\\{0.01x,x\\}$ is convex.",
            "A combination of ReLUs such as $ReLU(x) - ReLU(x-1)$ is convex.",
            "The loss $\\log \\sigma(x)= -\\log(1+e^{-x})$ is concave"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the options provided and recognize that one of them must be incorrect, as the question is asking for a false statement.\", \"instruction 2\": \"Carefully evaluate each option, considering any relevant context, definitions, or relationships between the options, to determine which one does not align with the truth or is an incorrect statement.\" }\n\nPlease provide your response in the same format as the examples above. \n\nPlease note that the original question is:\n\nWhat is the primary purpose of the “conceptual framework” in a research paper?\n\nPlease provide the instructions in the format of a JSON object with two key-value pairs, where the key is the instruction number and the value is the specific instruction. \n\nPlease provide your response in the following format:\n\n{\n  \"instruction 1\": \"Instruction 1 content",
        "instruction 2": "Carefully evaluate each option, considering any relevant context, definitions, or relationships between the options, to determine which one does not align with the truth or is an incorrect statement.\" }\n\nPlease provide your response in the same format as the examples above. \n\nPlease note that the original question is:\n\nWhat is the primary purpose of the “conceptual framework” in a research paper?\n\nPlease provide the instructions in the format of a JSON object with two key-value pairs, where the key is the instruction number and the value is the specific instruction. \n\nPlease provide your response in the following format:\n\n{\n  \"instruction 1\": \"Instruction 1 content"
    },
    {
        "question": "We are training fully connected network with two hidden layers to predict housing prices. Inputs are $100$-dimensional, and have several features such as the number of square feet, the median family income, etc. The first hidden layer has $1000$ activations. The second hidden layer has $10$ activations. The output is a scalar representing the house price. Assuming a vanilla network with affine transformations and with no batch normalization and no learnable parameters in the activation function, how many parameters does this network have?",
        "answer": 0,
        "choices": [
            "111021",
            "110010",
            "111110",
            "110011"
        ],
        "subject": "machine_learning",
        "instruction 1": "Calculate the number of weights in the first hidden layer, considering the input dimension, the number of activations in the first hidden layer, and the fact that each input feature is connected to each activation.",
        "instruction 2": "Calculate the number of weights in the second hidden layer, considering the number of activations in the first hidden layer, the number of activations in the second hidden layer, and the fact that each activation in the first hidden layer is connected to each activation in the second hidden layer."
    },
    {
        "question": "Statement 1| The derivative of the sigmoid $\\sigma(x)=(1+e^{-x})^{-1}$ with respect to $x$ is equal to $\\text{Var}(B)$ where $B\\sim \\text{Bern}(\\sigma(x))$ is a Bernoulli random variable. Statement 2| Setting the bias parameters in each layer of neural network to 0 changes the bias-variance trade-off such that the model's variance increases and the model's bias decreases",
        "answer": 2,
        "choices": [
            "True, True",
            "False, False",
            "True, False",
            "False, True"
        ],
        "subject": "machine_learning",
        "instruction 1": "Identify the key components in Statement 1, including the sigmoid function, the derivative, and the Bernoulli random variable, and explain how they relate to each other.",
        "instruction 2": "Consider the implications of setting bias parameters to 0 in a neural network, analyzing how this affects the trade-off between bias and variance, and explaining the resulting changes in model performance."
    }
]